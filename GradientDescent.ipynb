{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0195cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d640e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442, 1)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "X = pd.DataFrame(diabetes.data,columns=diabetes.feature_names)\n",
    "y = pd.DataFrame(diabetes.target,columns=['target'])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24987c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "# diabetes = load_diabetes()\n",
    "# diabetes.keys()\n",
    "X,y = load_diabetes(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7989b45",
   "metadata": {},
   "source": [
    "In Python, (10,) is a one-tuple (the , being necessary to distinguish it from the use of parentheses for grouping: (10) just means 10), whereas (10,1) is a pair (a 2-tuple). So np.ones((10,)) creates a one-dimensional array of size 10, whereas np.ones((10,1)) creates a two-dimensional array of dimension 10Ã—1. This is directly analogous to, say, the difference between a single number and a one-dimensional array of length 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3931941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10) (89, 10) (353,) (89,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad959be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.34560453985995\n",
      "[  37.90402135 -241.96436231  542.42875852  347.70384391 -931.48884588\n",
      "  518.06227698  163.41998299  275.31790158  736.1988589    48.67065743]\n",
      "0.4526027629719195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)\n",
    "y_pred = lr.predict(X_test)\n",
    "score= r2_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c68cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGDRegressor:\n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        self.intercept=None\n",
    "        self.coef=None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs=epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.coef = np.ones(X_train.shape[1])\n",
    "        self.intercept = 0\n",
    "        for _ in range(self.epochs):\n",
    "            y_hat = self.intercept + np.dot(X_train,self.coef)\n",
    "            loss = y_train-y_hat\n",
    "            df_intercept = -2*np.mean(loss)\n",
    "            self.intercept = self.intercept - (self.learning_rate * df_intercept)\n",
    "            df_coef = -2*np.dot(loss,X_train)/X_train.shape[0]\n",
    "            self.coef = self.coef - (self.learning_rate * df_coef)\n",
    "        return self.intercept,self.coef\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        y_pred = np.dot(X_test,self.coef) + self.intercept\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a95df21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.372591059285\n",
      "[  41.82977756 -203.23644652  509.6557063   325.07401153  -71.07194191\n",
      " -119.33187737 -215.85264692  144.71021659  376.52729984  111.97619094]\n",
      "0.4588776166235029\n"
     ]
    }
   ],
   "source": [
    "bgd = BatchGDRegressor(epochs=1000,learning_rate=0.5)\n",
    "intercept,coef = bgd.fit(X_train,y_train)\n",
    "print(intercept)\n",
    "print(coef)\n",
    "y_pred = bgd.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426891ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  55.46264769 -106.32985493  384.06442669  262.17455583  -10.69020551\n",
      "  -50.15035438 -188.76630042  148.23826818  298.24881338  146.87104672]\n",
      "[154.1067503]\n",
      "0.45183977944990117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd = SGDRegressor(learning_rate='constant',eta0=0.01,warm_start=True)\n",
    "sgd.fit(X_train,y_train)\n",
    "print(sgd.coef_)\n",
    "print(sgd.intercept_)\n",
    "y_pred = sgd.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f65b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StocasticGDRegressor:\n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        self.intercept=None\n",
    "        self.coef=None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs=epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.coef = np.ones(X_train.shape[1])\n",
    "        self.intercept = 0\n",
    "        for _ in range(self.epochs):\n",
    "            for _ in range(X_train.shape[0]):\n",
    "                idx = np.random.randint(0,X_train.shape[0])\n",
    "                y_hat = self.intercept + np.dot(X_train[idx],self.coef)\n",
    "                loss = y_train[idx]-y_hat\n",
    "                df_intercept = -2*loss\n",
    "                self.intercept = self.intercept - (self.learning_rate * df_intercept)\n",
    "                df_coef = -2*np.dot(loss,X_train[idx])\n",
    "                self.coef = self.coef - (self.learning_rate * df_coef)\n",
    "        return self.intercept,self.coef\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        y_pred = np.dot(X_test,self.coef) + self.intercept\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abe39ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167.9925039579993\n",
      "[  12.563505   -256.39027677  579.82838362  332.60177854 -186.04136159\n",
      "  -65.07458623 -195.76948479  151.42450797  461.00413586   44.70253727]\n",
      "0.43055146784853027\n"
     ]
    }
   ],
   "source": [
    "# SGD needs less epochs - here # of gradient update = epochs * n\n",
    "sgd = StocasticGDRegressor(epochs=100,learning_rate=0.1)\n",
    "intercept,coef = sgd.fit(X_train,y_train)\n",
    "print(intercept)\n",
    "print(coef)\n",
    "y_pred = sgd.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87b2789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32.23477084  -8.87458169 117.67526137  83.89565739  26.62794724\n",
      "  15.42120581 -71.90362873  74.87909418 107.00275493  69.29421118]\n",
      "[149.01781488]\n",
      "0.2710105748004237\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "sgd = SGDRegressor(learning_rate='constant',eta0=0.01,warm_start=True)\n",
    "for _ in range(epochs):\n",
    "    idx = random.sample(range(X_train.shape[0]),batch_size)\n",
    "    sgd.partial_fit(X_train[idx],y_train[idx])\n",
    "\n",
    "print(sgd.coef_)\n",
    "print(sgd.intercept_)\n",
    "y_pred = sgd.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44f1e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatchGDRegressor:\n",
    "    def __init__(self,batch_size=1,learning_rate=0.01,epochs=100):\n",
    "        self.intercept=None\n",
    "        self.coef=None\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs=epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.coef = np.ones(X_train.shape[1])\n",
    "        self.intercept = 0\n",
    "        for _ in range(self.epochs):\n",
    "            for _ in range(int(X_train.shape[0]/self.batch_size)):\n",
    "                idx = random.sample(range(X_train.shape[0]),self.batch_size)\n",
    "                y_hat = self.intercept + np.dot(X_train[idx],self.coef)\n",
    "                loss = y_train[idx]-y_hat\n",
    "                df_intercept = -2*np.mean(loss)\n",
    "                self.intercept = self.intercept - (self.learning_rate * df_intercept)\n",
    "                df_coef = -2*np.dot(loss,X_train[idx])\n",
    "                self.coef = self.coef - (self.learning_rate * df_coef)\n",
    "        return self.intercept,self.coef\n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        y_pred = np.dot(X_test,self.coef) + self.intercept\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a463bbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.34777745632272\n",
      "[  60.51125733 -234.68484735  556.16769404  325.05564641 -178.46339557\n",
      "  -58.80419932 -196.24675531  177.9268573   461.18325203   51.89122214]\n",
      "0.4432935080955057\n"
     ]
    }
   ],
   "source": [
    "# batch_size = int(X_train.shape[0]/50)\n",
    "mbgd = MiniBatchGDRegressor(epochs=100,learning_rate=0.1,batch_size=8)\n",
    "intercept,coef = mbgd.fit(X_train,y_train)\n",
    "print(intercept)\n",
    "print(coef)\n",
    "y_pred = mbgd.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e13b07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
